# -*- coding: utf-8 -*-
"""chinese_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ne69RY220XlN0-vKh0q82ElnOjGv415w

# Chinese Dataset

## Import Libs
"""

# Commented out IPython magic to ensure Python compatibility.
#basic libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()

#machine learning libraries
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, f1_score
from xgboost import XGBClassifier

#removing warnings
import warnings
warnings.filterwarnings("ignore")

#plot in jupyter notebook
# %matplotlib inline

#when using colab I like to do this to access the files in drive
#if running in a local pc: 
#           comment this cell
#           change the files' path
from google.colab import drive
drive.mount("/content/gdrive")

"""## First Training

### Read Data

Reading the dataset, dropping the *Admission* and *Discharge* times (not important) and then group by *Patient ID*.
"""

df = pd.read_excel("gdrive/MyDrive/Bolsa - NeuroComp/datasets/time_series_375_prerpocess_en.xlsx",
                   index_col=[0,1])
df = df.drop(columns=['Admission time', 'Discharge time']) #info not important
df = df.groupby('PATIENT_ID').first()

df.head()

"""Fiding NaN values in my dataset"""

#find NaN values
miss_data = df.isna().mean().sort_values(ascending=True) 

#color func
my_cmap = plt.get_cmap("viridis")
rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))

#plot 
fig, ax = plt.subplots(figsize=(12, 14))

#ax.tick_params(axis='both', which='major', labelsize=8)
plt.xlabel('Percent of NaN Values')
plt.barh(miss_data.index, miss_data, color=my_cmap(rescale(miss_data)))

plt.show()

"""We're gonne use only data with less than 20% of NaN values (darker ones)"""

nan_value = 0.2 #percent of NaN values
sel_col = df.columns[(df.isna().mean() <= nan_value).values]

#df[sel_col].head()

"""### Separating Values

Separating the data set in features e results
"""

X = df.drop(columns=["outcome"]) #labels - drop outcome (feature)
y = df.outcome #feature - dead or alive 

import_feature = pd.DataFrame(columns=X.columns)

X.head(100)

"""### Training

XGBoost Read the Docs [[4]](https://xgboost.readthedocs.io/en/latest/python/python_api.html)
"""

tmax = 500 #100, 150, 200

for i in range(tmax): 
    X_train, X_test, y_train, y_test = train_test_split(X,
                                                        y,
                                                        test_size=0.3,
                                                        random_state=i) #state for iteration
    
    model = XGBClassifier(max_depth=4, #Maximum tree depth for base learners.
                          learning_rate=0.2, #Boosting learning rate (xgb’s “eta”)
                          reg_lambda=1, #L2 regularization term on weights
                          n_estimators=150, #Number of boosting rounds.
                          subsample = 0.9, #Subsample ratio of the training instance.
                          colsample_bytree = 0.9) #Subsample ratio of columns when constructing each tree.
    
    model.fit(X_train, y_train)
    import_feature = import_feature.append(pd.DataFrame(model.feature_importances_,
                                                        index=X.columns).transpose())

X_best = X[import_feature.mean().sort_values(ascending=False).head(5).index]

X_best.head()

"""### Evaluate Model"""

X_train, X_test, y_train, y_test = train_test_split(X_best, #x = x_best
                                                    y, #same
                                                    test_size=0.3, #same
                                                    random_state=3463) #def state

model = XGBClassifier(max_depth=4,
                      learning_rate=0.2,
                      reg_lambda=1,
                      n_estimators=150,
                      subsample=0.9,
                      colsample_bytree=0.9,
                      verbosity=0)

model.fit(X_train,y_train)

"""### Predicting"""

predict_labels = model.predict(X_test)
c_matrix = confusion_matrix(y_test, predict_labels)

"""### Confusion Matrix

making a confusion matrix

plotting the confusion matrix more visible
"""

#making labels
group_counts = ['{0:0.0f}'.format(value) for value in c_matrix.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in c_matrix.flatten()/np.sum(c_matrix)]
labels = [f'{v1}\n{v2}' for v1, v2 in zip(group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)

#plot
fig, ax = plt.subplots(figsize=(16, 12))
sns.heatmap(c_matrix, annot=labels, fmt='', cmap="YlGnBu")#, cmap='Blues', cbar=True)

#axis labels
ticks_labels = ['Survivals', 'Deaths']
plt.xticks(np.arange(2) + .5, labels=ticks_labels, fontsize=14)
plt.yticks(np.arange(2) + .5, labels=ticks_labels, fontsize=14)

plt.xlabel('Predicted Label', fontsize=20)
plt.ylabel('True Label', fontsize=20)

#title
plt.title('Confusion Matrix', fontsize=30)

#show
plt.show()

"""### Model Reliability  (I guess?)

F-score in wiki [here](https://en.wikipedia.org/wiki/F-score).
"""

f1_score(y_test, predict_labels)

"""## Second Training

### Read Data

NLR = Neutrophil to Lymphocyte Ratio [[5]](https://en.wikipedia.org/wiki/Neutrophil_to_lymphocyte_ratio)
"""

#same thing as done before
df2 = pd.read_excel("gdrive/MyDrive/Bolsa - NeuroComp/datasets/time_series_375_prerpocess_en.xlsx",
                    index_col=[0,1])
df2 = df2.drop(columns=['Admission time', 'Discharge time'])
df2 = df2.groupby('PATIENT_ID').first()

nan_value = 0.2 #percent of NaN values
sel_col2 = df2.columns[(df2.isna().mean() <= nan_value).values]
df2 = df2[sel_col2]

#??????? drop some random labels ??????
df2["NLR"] = df2['neutrophils count'] / df2['lymphocyte count'] #??????
df2.drop(labels=['lymphocyte count', #l34
                 'neutrophils count', #l41
                 'neutrophils(%)', #l21
                 '(%)lymphocyte'], #l47
         axis=1,
         inplace=True)

df2.head()

"""### Separating Values"""

X2 = df2.drop(columns=["outcome"])
y2 = df2.outcome

import_feature2 = pd.DataFrame(columns=X2.columns)

"""### Training"""

tmax = 50 #100, 150, 200

for i in range(tmax):
    X2_train, X2_test, y2_train, y2_test = train_test_split(X2,
                                                            y2,
                                                            test_size=0.3,
                                                            random_state=i) #state for iteration
    
    model2 = XGBClassifier(max_depth=4,
                           learning_rate=0.2,
                           reg_lambda=1,
                           n_estimators=150,
                           subsample=0.9,
                           colsample_bytree=0.9,
                           verbosity=0)
    
    model2.fit(X2_train, y2_train)
    import_feature2 = import_feature2.append(pd.DataFrame(model2.feature_importances_,
                                                          index=X2.columns).transpose())

X2_best = X2[import_feature2.mean().sort_values(ascending=False).head(5).index]
X2_best

pd.DataFrame(import_feature2.mean().sort_values(ascending=False).head(15))

"""### Evaluate Model"""

X2_train, X2_test, y2_train, y2_test = train_test_split(X2_best,
                                                        y2,
                                                        test_size=0.3,
                                                        random_state=3463)

model2 = XGBClassifier(max_depth=4,
                       learning_rate=0.2,
                       reg_lambda=1,
                       n_estimators=150,
                       subsample = 0.9,
                       colsample_bytree = 0.9)

model2.fit(X2_train, y2_train)

"""### Predicting"""

predict_labels2 = model2.predict(X2_test)
c_matrix2 = confusion_matrix(y2_test, predict_labels2)

"""### Confusion Matrix

making confusion matrix more visible
"""

#making labels
group_counts = ['{0:0.0f}'.format(value) for value in c_matrix2.flatten()]
group_percentages = ['{0:.2%}'.format(value) for value in c_matrix2.flatten()/np.sum(c_matrix2)]
labels = [f'{v1}\n{v2}' for v1, v2 in zip(group_counts,group_percentages)]
labels = np.asarray(labels).reshape(2,2)

#plot
fig, ax = plt.subplots(figsize=(16, 12))
sns.heatmap(c_matrix2, annot=labels, fmt='', cmap="YlGnBu")#, cmap='Blues', cbar=True)

#axis labels
ticks_labels = ['Survivals', 'Deaths']
plt.xticks(np.arange(2) + .5, labels=ticks_labels, fontsize=14)
plt.yticks(np.arange(2) + .5, labels=ticks_labels, fontsize=14)

plt.xlabel('Predicted Label', fontsize=20)
plt.ylabel('True Label', fontsize=20)

#title
plt.title('Confusion Matrix', fontsize=30)

#show
plt.show()

"""### Model Reliability"""

f1_score(y_test, predict_labels)

"""## BoxPlots

### NLR of Dead or Alive
"""

plt.figure(figsize=(20,6))
sns.boxplot(df2[df2.outcome == 0].NLR, color="b")

plt.figure(figsize=(20,6))
sns.boxplot(df2[df2.outcome == 1].NLR, color="r")

"""### Hypersensitive C-Reative Protein"""

plt.figure(figsize=(20,6))
sns.boxplot(df[df.outcome == 0]["Hypersensitive c-reactive protein"], color="b")

plt.figure(figsize=(20,6))
sns.boxplot(df[df.outcome == 1]["Hypersensitive c-reactive protein"], color="r")
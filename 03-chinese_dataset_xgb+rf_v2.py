# -*- coding: utf-8 -*-
"""chinese_dataset_XGB+RF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1npSWaLsoO53NKBapB0UwQ1rkRWuCm4HZ

# Chinese Dataset

Random Forest and XGBoost: Using Emsemble Machine Learning Algorithms to predict COVID-19 outcome.

Based on *'An interpretable mortality prediction model for
COVID-19 patients'*. Source [here](https://doi.org/10.1038/s42256-020-0180-7).

## Preps

### Import Libs
"""

# Commented out IPython magic to ensure Python compatibility.
#basic libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns; sns.set()

#machine learning libraries
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, f1_score, classification_report
from xgboost import XGBClassifier
from xgboost import XGBRFClassifier
from xgboost import plot_tree

#removing warnings
import warnings
warnings.filterwarnings("ignore")

#plot in jupyter notebook
# %matplotlib inline

#when using colab I like to do this to access the files in drive
#if running in a local pc: 
#           comment this cell
#           change the files' path
from google.colab import drive
drive.mount("/content/gdrive")

"""### Save Plots"""

save = 0   # save figs
#save = 1    # don't save figs

"""## Manipulating Data

### Read Data

Reading the dataset, dropping the *Admission* and *Discharge* times (not important) and then group by *Patient ID*.
"""

df = pd.read_excel("gdrive/MyDrive/Bolsa - NeuroComp/datasets/time_series_375_prerpocess_en.xlsx",
                   index_col=[0,1])
df = df.drop(columns=['Admission time', 'Discharge time']) #info not important
df = df.groupby('PATIENT_ID').first()

df

"""### Find NaN Values and Remove

Fiding NaN values in my dataset
"""

#find NaN values
miss_data = df.isna().mean().sort_values(ascending=True) 

#color func
my_cmap = plt.get_cmap("viridis")
rescale = lambda y: (y - np.min(y)) / (np.max(y) - np.min(y))

#plot 
fig, ax = plt.subplots(figsize=(12, 14))

#ax.tick_params(axis='both', which='major', labelsize=8)
plt.xlabel('Percent of NaN Values')
plt.barh(miss_data.index, miss_data, color=my_cmap(rescale(miss_data)))
plt.axvline(0.2, color='red')

if (save == 0):
    plt.savefig('missing_data.png')

plt.show()

"""We're gonne use only data with less than 20% of NaN values (darker ones)"""

nan_value = 0.2 #percent of NaN values

df = df.loc[:, df.isnull().mean() < nan_value]
df

"""Removing spaces """

df.columns = df.columns.str.replace(" ", "_")

"""### Separating Values

Separating the data set in features and labels
"""

X = df.drop(columns=["outcome"])    #features
y = df.outcome                      #target

"""## Frequent Functions

### Important Features Plot
"""

def important_features_plot(imp, model_name, filename):
    #find more important values
    mi = imp.mean().sort_values(ascending=True) 

    #plot 
    fig, ax = plt.subplots(figsize=(12, 14))

    plt.title('Important Features: ' + model_name, fontsize=20)
    plt.xlabel('Mean of More Important Features', fontsize=10)

    sns.barplot(mi, mi.index)

    if (save==0):
        plt.savefig(filename)

    plt.show()

"""### Confusion Matrix Plot"""

def confusion_matrix_plot(cm, model_name, filename):
    #making labels
    group_counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]
    group_percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]
    labels = [f'{v1}\n{v2}' for v1, v2 in zip(group_counts,group_percentages)]
    labels = np.asarray(labels).reshape(2,2)

    #plot
    fig, ax = plt.subplots(figsize=(12, 12))
    sns.heatmap(cm, annot=labels, fmt='', cmap="YlGnBu")#, cmap='viridis', cbar=True)
    ax.set_aspect('equal', adjustable='box')
    
    #axis labels
    ticks_labels = ['Survivals', 'Deaths']
    plt.xticks(np.arange(2) + .5, labels=ticks_labels, fontsize=14)
    plt.yticks(np.arange(2) + .5, labels=ticks_labels, fontsize=14)
    
    plt.xlabel('Predicted Label', fontsize=20)
    plt.ylabel('True Label', fontsize=20)
    
    #title
    plt.title('Confusion Matrix: '+ model_name, fontsize=30)

    if (save==0):
        plt.savefig(filename)
                
    #show
    plt.show()

"""### Decision Tree Plot"""

def decision_tree_plot(model, model_name, filename):
    fig = plt.figure(figsize=(16, 9))
    ax = plt.subplot(1,1,1)
            
    plot_tree(model, ax = ax)
    plt.title('Decision Tree: '+ model_name, fontsize=30)

    plt.tight_layout()
            
    if (save==0):
        plt.savefig(filename)

    plt.show()

"""### Feature Plot

"""

def twod_feature_plot(y, feature, filename):
    fig = plt.figure(figsize=(10, 9))

    plt.title('Outcome and '+ feature.name, fontsize=30)
    ticks = [0, 1]
    labels = ["Survivals", "Deaths"]

    plt.yticks(ticks, labels)

    plt.scatter(feature, y)

    if (save==0):
        plt.savefig(filename)

    plt.show()

"""## Training - Random Forest

XGBoost Read the Docs [[4]](https://xgboost.readthedocs.io/en/latest/python/python_api.html)

XGBoost parameters [[5]](https://xgboost.readthedocs.io/en/latest/parameter.html)
"""

import_feature_RF = pd.DataFrame(columns=X.columns)

tmax = 50 #100, 150, 200

for i in range(tmax): 
    X_train, X_test, y_train, y_test = train_test_split(X,
                                                        y,
                                                        test_size=0.3,
                                                        random_state=i) #state for iteration
    
    model_RF = XGBRFClassifier(max_depth=4,             #Maximum tree depth for base learners.
                               learning_rate=0.2,       #learning rate (“eta”)
                               reg_lambda=1,            #L2 regularization term on weights
                               n_estimators=150,        #Number of boosting rounds.
                               subsample = 0.9,         #Subsample ratio of the training instance.
                               colsample_bytree = 0.9)  #Subsample ratio of columns when constructing each tree.
    
    model_RF.fit(X_train, y_train)
    import_feature_RF = import_feature_RF.append(pd.DataFrame(model_RF.feature_importances_,
                                                              index=X.columns).transpose())

"""### Feature Importance"""

important_features_plot(import_feature_RF, 'Random Forest', 'imp_rf.png')

"""choosing the five best ones"""

X_best_RF = X[import_feature_RF.mean().sort_values(ascending=False).head(5).index]
X_best_RF

"""### Evaluate Model"""

X_train, X_test, y_train, y_test = train_test_split(X_best_RF, #x = x_best
                                                    y, #same
                                                    test_size=0.3, #same
                                                    random_state=3463) #def state

model_RF = XGBRFClassifier(max_depth=4,
                           learning_rate=0.2,
                           reg_lambda=1,
                           n_estimators=150,
                           subsample=0.9,
                           colsample_bytree=0.9,
                           verbosity=0)

model_RF.fit(X_train,y_train)

"""### Predicting"""

predict_labels = model_RF.predict(X_test)
c_matrix_RF = confusion_matrix(y_test, predict_labels)

"""### Confusion Matrix"""

confusion_matrix_plot(c_matrix_RF, 'Random Forest', 'cm_rf.png')

"""### Model Reliability

F-score in wiki [here](https://en.wikipedia.org/wiki/F-score).
"""

f1_score(y_test, predict_labels)

"""saving for classification reports"""

y_test_RF, predict_labels_RF = y_test, predict_labels

"""### Tree Plot"""

decision_tree_plot(model_RF, 'Random Forest', "tree_rf.png")

"""## Training - XGBoost

XGBoost Read the Docs [[4]](https://xgboost.readthedocs.io/en/latest/python/python_api.html)

XGBoost parameters [[5]](https://xgboost.readthedocs.io/en/latest/parameter.html)
"""

import_feature_XGB = pd.DataFrame(columns=X.columns)

tmax = 50 #100, 150, 200

for i in range(tmax): 
    X_train, X_test, y_train, y_test = train_test_split(X,
                                                        y,
                                                        test_size=0.3,
                                                        random_state=i) #state for iteration
    
    model_XGB = XGBClassifier(max_depth=4, #Maximum tree depth for base learners.
                              learning_rate=0.2, #learning rate (“eta”)
                              reg_lambda=1, #L2 regularization term on weights
                              n_estimators=150, #Number of boosting rounds.
                              subsample = 0.9, #Subsample ratio of the training instance.
                              colsample_bytree = 0.9) #Subsample ratio of columns when constructing each tree.
    
    model_XGB.fit(X_train, y_train)
    import_feature_XGB = import_feature_XGB.append(pd.DataFrame(model_XGB.feature_importances_,
                                                                index=X.columns).transpose())

"""### Feature Importance"""

important_features_plot(import_feature_XGB, 'XGBoost', 'imp_xgb.png')

"""choosing the five best ones"""

X_best_XGB = X[import_feature_XGB.mean().sort_values(ascending=False).head(5).index]
X_best_XGB

"""### Evaluate Model"""

X_train, X_test, y_train, y_test = train_test_split(X_best_XGB, #x = x_best
                                                    y, #same
                                                    test_size=0.3, #same
                                                    random_state=3463) #def state

model_XGB = XGBClassifier(max_depth=4,
                         learning_rate=0.2,
                         reg_lambda=1,
                         n_estimators=150,
                         subsample=0.9,
                         colsample_bytree=0.9,
                         verbosity=0)

model_XGB.fit(X_train,y_train)

"""### Predicting"""

predict_labels = model_XGB.predict(X_test)
c_matrix_XGB = confusion_matrix(y_test, predict_labels)

"""### Confusion Matrix"""

confusion_matrix_plot(c_matrix_XGB, 'XGBoost', 'cm_xgb.png')

"""### Model Reliability

F-score in wiki [here](https://en.wikipedia.org/wiki/F-score).
"""

f1_score(y_test, predict_labels)

"""saving for classification reports"""

y_test_XGB, predict_labels_XGB = y_test, predict_labels

"""### Tree Plot"""

decision_tree_plot(model_XGB, 'XGBoost', "tree_xgb.png")

"""## Plots of Most Important Features"""

twod_feature_plot(y, X['Lactate_dehydrogenase'], "lactate.png")

twod_feature_plot(y, X['neutrophils(%)'], "neutr.png")

twod_feature_plot(y, X['(%)lymphocyte'], "lymp.png")

twod_feature_plot(y, X['procalcitonin'], "proc.png")

twod_feature_plot(y, X['neutrophils_count'], "neu-c.png")

"""## Classification Reports

### Theory

Comparision between both methods.

Precision (column):
\begin{aligned}
    P = \frac{TP}{TP + FP}
\end{aligned}

Recall (row):
\begin{aligned}
    R = \frac{TP}{TP+FN}
\end{aligned}

F1-Score (model confiability):
\begin{aligned}
    F1 = 2 \frac{R \cdot P}{R+P} = \frac{TP}{TP+FN+FP}
\end{aligned}

Where $TP$ is True-Positive, $TN$ is True-Negative, $FP$ is False-Positive and $FN$ is False-Negative.

### Random Forest
"""

print("Random Forest")
print("")
print("Classification Report")
print("---------------------")
print(classification_report(y_test_RF, predict_labels_RF, target_names=['Survivals', 'Deaths']))
print("Confusion Matrix")
print("----------------")
print(c_matrix_RF)

"""### XGBoost"""

1385
print("Classification Report")
print("---------------------")
print(classification_report(y_test_XGB, predict_labels_XGB, target_names=['Survivals', 'Deaths']))
print("Confusion Matrix")
print("----------------")
print(c_matrix_XGB)